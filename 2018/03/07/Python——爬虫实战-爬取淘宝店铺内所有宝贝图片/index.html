<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      Python——爬虫实战 爬取淘宝店铺内所有宝贝图片 | Leon的博客 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="李晓">
    
    

    <meta name="description" content="之前用四篇很啰嗦的入门级别的文章，带着大家一起去了解并学习在编写爬虫的过程中，最基本的几个库的用法。 那么今天，我们就正式开始我们的第一篇实战内容，爬取一整个淘宝店铺里的所有宝贝的详情页，并且把详情页里的宝贝图片保存下来。我自己刚开了一个小网店，当时写出这个爬虫，也是真真正正的为我自己服务了一回呢。 在写之前，我先把这个爬虫的代码分析一下，方便大家在看代码的时候，理解整个流程是怎么样的。">
<meta name="keywords" content="Python,爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="Python——爬虫实战 爬取淘宝店铺内所有宝贝图片 | Leon的博客">
<meta property="og:url" content="http://yoursite.com/2018/03/07/Python——爬虫实战-爬取淘宝店铺内所有宝贝图片/index.html">
<meta property="og:site_name" content="Leon的博客">
<meta property="og:description" content="之前用四篇很啰嗦的入门级别的文章，带着大家一起去了解并学习在编写爬虫的过程中，最基本的几个库的用法。 那么今天，我们就正式开始我们的第一篇实战内容，爬取一整个淘宝店铺里的所有宝贝的详情页，并且把详情页里的宝贝图片保存下来。我自己刚开了一个小网店，当时写出这个爬虫，也是真真正正的为我自己服务了一回呢。 在写之前，我先把这个爬虫的代码分析一下，方便大家在看代码的时候，理解整个流程是怎么样的。">
<meta property="og:updated_time" content="2018-03-06T23:07:16.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python——爬虫实战 爬取淘宝店铺内所有宝贝图片 | Leon的博客">
<meta name="twitter:description" content="之前用四篇很啰嗦的入门级别的文章，带着大家一起去了解并学习在编写爬虫的过程中，最基本的几个库的用法。 那么今天，我们就正式开始我们的第一篇实战内容，爬取一整个淘宝店铺里的所有宝贝的详情页，并且把详情页里的宝贝图片保存下来。我自己刚开了一个小网店，当时写出这个爬虫，也是真真正正的为我自己服务了一回呢。 在写之前，我先把这个爬虫的代码分析一下，方便大家在看代码的时候，理解整个流程是怎么样的。">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css">

</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">Leon的博客</a></h1>
        <hr class="panel-cover__divider" />

        
        <p class="panel-cover__description">
          每多学一点知识，就少写一行代码
        </p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">

    
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/originalix" title="Huno on GitHub">
          <i class='icon icon-social-github'></i>
          <span class="label">GitHub</span>
        </a>
      </li>
    

    <!-- China social icon -->
    <!--
    
      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>

      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

    -->



  </ul>
</nav>



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">

    <h1 class="post-title">Python——爬虫实战 爬取淘宝店铺内所有宝贝图片</h1>

    

    <div class="post-meta">
      <time datetime="2018-03-07" class="post-meta__date date">2018-03-07</time>

      <span class="post-meta__tags tags">

          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/Python/">Python</a>, <a class="tags-link" href="/tags/爬虫/">爬虫</a>
            </font>
          

      </span>


      <span class="post-meta_statistic date" id="busuanzi_container_page_pv">
        本文总阅读量<span id="busuanzi_value_page_pv"></span>次
      </span>

    </div>

    

  </header>

  <section id="post-content" class="article-content post">
    <p>之前用四篇很啰嗦的入门级别的文章，带着大家一起去了解并学习在编写爬虫的过程中，最基本的几个库的用法。</p>
<p>那么今天，我们就正式开始我们的第一篇实战内容，爬取一整个淘宝店铺里的所有宝贝的详情页，并且把详情页里的宝贝图片保存下来。我自己刚开了一个小网店，当时写出这个爬虫，也是真真正正的为我自己服务了一回呢。</p>
<p>在写之前，我先把这个爬虫的代码分析一下，方便大家在看代码的时候，理解整个流程是怎么样的。</p>
<a id="more"></a>
<p>爬虫框架我一直是使用Scrapy的，在用Scrapy抓取店铺信息的时候，因为淘宝的反爬机制，发现了机器人，所以获取不到任何信息，当时我赶着用宝贝图片，所以我使用了之前介绍的selenium来获取网页信息，并且通过我们上一篇介绍的lxml框架来提取信息。最主要的库就是这两个，那么我针对这个爬虫，编写了一个叫做<code>taobaoShop</code>的爬虫类。</p>
<p>之后，我们首先进入店铺的首页，抓取首页所有商品的资料，并用他们的宝贝名，来生成文件夹，方便存储对应的详情图片，然后爬虫进入宝贝的详情页，从详情页中提取详情照片，并且保存在宝贝名称对应的文件夹中，在该页面所有的宝贝爬取完成后，咱们后检查是否有分页，如果还有下一页的宝贝，那么进入下一页的宝贝接着爬，过程就和刚刚描述的一样了。</p>
<p>所以我们的淘宝店铺爬虫类的初始化代码是这样的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""初始化构造函数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    self.site_url = <span class="string">'https://shop67309167.taobao.com/?spm=a230r.7195193.1997079397.2.xPZZS0'</span></span><br><span class="line">    self.driver = webdriver.Chrome()</span><br><span class="line">    self.sleep_time = <span class="number">10</span></span><br><span class="line">    self.save_img_path = <span class="string">'/Users/Lix/Documents/tbshop/'</span></span><br></pre></td></tr></table></figure>
<p>初始化中我们设置了要爬取的店铺url（这就是我的小店，如果可以的话，请各位大佬帮忙点个关注），另外是启动selenium中webdriver的代码，我用Chrome打开，静默的话可以选择Phantomjs打开，另外有个间歇时间，因为爬取的过快，会被淘宝判定为爬虫，弹出登录框，最后的<code>save_img_path</code>自然就是我保存图片的路径了。</p>
<p>在初始化的构造函数完成之后，我们首先获取的是淘宝店铺页面的网页信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""获取淘宝店铺页面代码</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    self.driver.get(self.site_url)</span><br><span class="line">    time.sleep(self.sleep_time)</span><br><span class="line">    content = self.driver.page_source.encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="keyword">print</span> self.driver.title</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 保存html代码debug</span></span><br><span class="line">    <span class="comment"># self.saveHtml('taobaoshop', content)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分析该页面的每个宝贝</span></span><br><span class="line">    self.getItem()</span><br></pre></td></tr></table></figure>
<p>在获取到店铺的网页信息后，我们调用<code>getItem()</code>函数，获取每个宝贝的信息:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getItem</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""爬取当前页面的每个宝贝，</span></span><br><span class="line"><span class="string">       提取宝贝名字，价格，标题等信息</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    html = self.driver.page_source.encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    selector = etree.HTML(html)</span><br><span class="line">    itemList = selector.xpath(<span class="string">"//div[@class='item3line1']"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 循环遍历该页所有商品</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> item3line1 <span class="keyword">in</span> itemList:</span><br><span class="line">        dl = item3line1.xpath(<span class="string">"./dl"</span>)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> dl:</span><br><span class="line">            link = <span class="string">'https:'</span> + item.xpath(<span class="string">"./dt/a/@href"</span>)[<span class="number">0</span>]</span><br><span class="line">            photo = <span class="string">'https:'</span> + item.xpath(<span class="string">"./dt/a/img/@src"</span>)[<span class="number">0</span>]</span><br><span class="line">            title = item.xpath(<span class="string">"./dd/a/text()"</span>)[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">            res = &#123;</span><br><span class="line">                <span class="string">'link'</span> : link,</span><br><span class="line">                <span class="string">'photo'</span> : photo,</span><br><span class="line">                <span class="string">'title'</span> : title</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 进入宝贝详情页 开始爬取里面的图片资料</span></span><br><span class="line">            self.getItemDetail(link, <span class="string">''</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取分页信息</span></span><br><span class="line">    pagination = selector.xpath(<span class="string">"//div[@class='pagination']/a[contains(@class, 'J_SearchAsync') and contains(@class, 'next')]/@href"</span>)</span><br><span class="line">    <span class="keyword">print</span> pagination</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'正在准备切换分页'</span></span><br><span class="line">    <span class="keyword">if</span> len(pagination) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'没有下一页了'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'加载下一页内容'</span></span><br><span class="line">        self.site_url = <span class="string">'https:'</span> + pagination[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">print</span> self.site_url</span><br><span class="line">        self.getPage()</span><br><span class="line">```            </span><br><span class="line"></span><br><span class="line">在这里，我们看到我们已经获取到了宝贝的链接，封面图，标题。并且执行了`getItemDetail(self, link, save_img_path)`函数去爬取宝贝的详情页了，最后我们还在循环结束之后，分析了分页数据。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">那么最后，我们就来看看最关键的`getItemDetail()`函数，看看是怎么爬取宝贝信息的:</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getItemDetail</span><span class="params">(self, link, save_img_path)</span>:</span></span><br><span class="line">    <span class="string">"""从宝贝的详情链接里 爬取图片</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        link &#123;String&#125; -- [宝贝详情链接]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    newDriver = webdriver.Chrome()</span><br><span class="line">    newDriver.get(link)</span><br><span class="line">    time.sleep(self.sleep_time)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> newDriver.title</span><br><span class="line"></span><br><span class="line">    img_dir_path = self.save_img_path + newDriver.title.encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">True</span> == self.mkdir(img_dir_path):</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'创建宝贝目录成功'</span></span><br><span class="line"></span><br><span class="line">    html = newDriver.page_source.encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    selector = etree.HTML(html)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 封面图</span></span><br><span class="line">    J_ULThumb = selector.xpath(<span class="string">"//div[@class='tb-gallery']/ul/li"</span>)</span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> J_ULThumb:</span><br><span class="line">        <span class="comment"># 替换图片 从50*50 至 400 * 400</span></span><br><span class="line">        <span class="keyword">if</span> len(li.xpath(<span class="string">"./div/a/img/@data-src"</span>)) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        small_pic = li.xpath(<span class="string">"./div/a/img/@data-src"</span>)[<span class="number">0</span>]</span><br><span class="line">        common_pic = <span class="string">'https:'</span> + small_pic.replace(<span class="string">'50x50'</span>, <span class="string">'400x400'</span>)</span><br><span class="line">        thumb_title = str(<span class="string">'封面图'</span>) + str(index)</span><br><span class="line">        <span class="keyword">print</span> thumb_title</span><br><span class="line">        <span class="comment"># self.saveImg(img_dir_path, common_pic, thumb_title.decode('utf-8'))</span></span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 爬取里面所有图片</span></span><br><span class="line">    all_img = selector.xpath(<span class="string">"//div[@id='J_DivItemDesc']//descendant::img/@src"</span>)</span><br><span class="line">    <span class="keyword">print</span> all_img</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> all_img:</span><br><span class="line">        imglink = img</span><br><span class="line">        <span class="keyword">if</span> img.startswith(<span class="string">'http'</span>) <span class="keyword">is</span> <span class="keyword">True</span>:</span><br><span class="line">            imglink = img</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            imglink = <span class="string">'https:'</span> + img</span><br><span class="line"></span><br><span class="line">        self.saveImg(img_dir_path, imglink, str(index))</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    newDriver.quit()</span><br></pre></td></tr></table></figure>
<p>注释都写在代码里了，大家看看就好，这里有很多地方的代码不够优雅，那是我当天急着用，所以后来也没有去优化了。</p>
<p>在这个核心解析代码的完成之后，宝贝图片就已经稳稳的存储到我们的硬盘上了，可以开箱即用了。完整的代码我也放在了<a href="https://github.com/originalix/Original/blob/master/python2.7/taobaoshop.py" target="_blank" rel="noopener">Github</a>上了，如果对您有帮助，请帮忙star一下。</p>

  </section>

  <section class="post-comments">

    <!-- 将评论系统（例如Disqus、多说、友言、畅言等）提供的代码片段粘贴在这里 -->
    
</section>


</article>


            <footer class="footer">
    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span class="footer__copyright">
        &copy; 2014-2018. | 由<a href="https://hexo.io/">Hexo</a>强力驱动
    </span>
    <span id="busuanzi_container_site_pv">
        本站访客数<span id="busuanzi_value_site_pv"></span>人次
    </span>

</footer>
        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

</body>
</html>
