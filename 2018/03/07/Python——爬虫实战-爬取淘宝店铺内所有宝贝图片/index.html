<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Python——爬虫实战 爬取淘宝店铺内所有宝贝图片 | Leon的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="之前用四篇很啰嗦的入门级别的文章，带着大家一起去了解并学习在编写爬虫的过程中，最基本的几个库的用法。 那么今天，我们就正式开始我们的第一篇实战内容，爬取一整个淘宝店铺里的所有宝贝的详情页，并且把详情页里的宝贝图片保存下来。我自己刚开了一个小网店，当时写出这个爬虫，也是真真正正的为我自己服务了一回呢。 在写之前，我先把这个爬虫的代码分析一下，方便大家在看代码的时候，理解整个流程是怎么样的。">
<meta name="keywords" content="Python,爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="Python——爬虫实战 爬取淘宝店铺内所有宝贝图片">
<meta property="og:url" content="http://yoursite.com/2018/03/07/Python——爬虫实战-爬取淘宝店铺内所有宝贝图片/index.html">
<meta property="og:site_name" content="Leon的博客">
<meta property="og:description" content="之前用四篇很啰嗦的入门级别的文章，带着大家一起去了解并学习在编写爬虫的过程中，最基本的几个库的用法。 那么今天，我们就正式开始我们的第一篇实战内容，爬取一整个淘宝店铺里的所有宝贝的详情页，并且把详情页里的宝贝图片保存下来。我自己刚开了一个小网店，当时写出这个爬虫，也是真真正正的为我自己服务了一回呢。 在写之前，我先把这个爬虫的代码分析一下，方便大家在看代码的时候，理解整个流程是怎么样的。">
<meta property="og:updated_time" content="2018-03-06T23:07:16.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python——爬虫实战 爬取淘宝店铺内所有宝贝图片">
<meta name="twitter:description" content="之前用四篇很啰嗦的入门级别的文章，带着大家一起去了解并学习在编写爬虫的过程中，最基本的几个库的用法。 那么今天，我们就正式开始我们的第一篇实战内容，爬取一整个淘宝店铺里的所有宝贝的详情页，并且把详情页里的宝贝图片保存下来。我自己刚开了一个小网店，当时写出这个爬虫，也是真真正正的为我自己服务了一回呢。 在写之前，我先把这个爬虫的代码分析一下，方便大家在看代码的时候，理解整个流程是怎么样的。">
  
    <link rel="alternate" href="/atom.xml" title="Leon的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Leon的博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">每多学一点知识，就少写一行代码</a>
        </h2>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Python——爬虫实战-爬取淘宝店铺内所有宝贝图片" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/07/Python——爬虫实战-爬取淘宝店铺内所有宝贝图片/" class="article-date">
  <time datetime="2018-03-06T23:04:01.000Z" itemprop="datePublished">2018-03-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python——爬虫实战 爬取淘宝店铺内所有宝贝图片
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>之前用四篇很啰嗦的入门级别的文章，带着大家一起去了解并学习在编写爬虫的过程中，最基本的几个库的用法。</p>
<p>那么今天，我们就正式开始我们的第一篇实战内容，爬取一整个淘宝店铺里的所有宝贝的详情页，并且把详情页里的宝贝图片保存下来。我自己刚开了一个小网店，当时写出这个爬虫，也是真真正正的为我自己服务了一回呢。</p>
<p>在写之前，我先把这个爬虫的代码分析一下，方便大家在看代码的时候，理解整个流程是怎么样的。</p>
<a id="more"></a>
<p>爬虫框架我一直是使用Scrapy的，在用Scrapy抓取店铺信息的时候，因为淘宝的反爬机制，发现了机器人，所以获取不到任何信息，当时我赶着用宝贝图片，所以我使用了之前介绍的selenium来获取网页信息，并且通过我们上一篇介绍的lxml框架来提取信息。最主要的库就是这两个，那么我针对这个爬虫，编写了一个叫做<code>taobaoShop</code>的爬虫类。</p>
<p>之后，我们首先进入店铺的首页，抓取首页所有商品的资料，并用他们的宝贝名，来生成文件夹，方便存储对应的详情图片，然后爬虫进入宝贝的详情页，从详情页中提取详情照片，并且保存在宝贝名称对应的文件夹中，在该页面所有的宝贝爬取完成后，咱们后检查是否有分页，如果还有下一页的宝贝，那么进入下一页的宝贝接着爬，过程就和刚刚描述的一样了。</p>
<p>所以我们的淘宝店铺爬虫类的初始化代码是这样的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""初始化构造函数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    self.site_url = <span class="string">'https://shop67309167.taobao.com/?spm=a230r.7195193.1997079397.2.xPZZS0'</span></span><br><span class="line">    self.driver = webdriver.Chrome()</span><br><span class="line">    self.sleep_time = <span class="number">10</span></span><br><span class="line">    self.save_img_path = <span class="string">'/Users/Lix/Documents/tbshop/'</span></span><br></pre></td></tr></table></figure>
<p>初始化中我们设置了要爬取的店铺url（这就是我的小店，如果可以的话，请各位大佬帮忙点个关注），另外是启动selenium中webdriver的代码，我用Chrome打开，静默的话可以选择Phantomjs打开，另外有个间歇时间，因为爬取的过快，会被淘宝判定为爬虫，弹出登录框，最后的<code>save_img_path</code>自然就是我保存图片的路径了。</p>
<p>在初始化的构造函数完成之后，我们首先获取的是淘宝店铺页面的网页信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""获取淘宝店铺页面代码</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    self.driver.get(self.site_url)</span><br><span class="line">    time.sleep(self.sleep_time)</span><br><span class="line">    content = self.driver.page_source.encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="keyword">print</span> self.driver.title</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 保存html代码debug</span></span><br><span class="line">    <span class="comment"># self.saveHtml('taobaoshop', content)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分析该页面的每个宝贝</span></span><br><span class="line">    self.getItem()</span><br></pre></td></tr></table></figure>
<p>在获取到店铺的网页信息后，我们调用<code>getItem()</code>函数，获取每个宝贝的信息:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getItem</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""爬取当前页面的每个宝贝，</span></span><br><span class="line"><span class="string">       提取宝贝名字，价格，标题等信息</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    html = self.driver.page_source.encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    selector = etree.HTML(html)</span><br><span class="line">    itemList = selector.xpath(<span class="string">"//div[@class='item3line1']"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 循环遍历该页所有商品</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> item3line1 <span class="keyword">in</span> itemList:</span><br><span class="line">        dl = item3line1.xpath(<span class="string">"./dl"</span>)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> dl:</span><br><span class="line">            link = <span class="string">'https:'</span> + item.xpath(<span class="string">"./dt/a/@href"</span>)[<span class="number">0</span>]</span><br><span class="line">            photo = <span class="string">'https:'</span> + item.xpath(<span class="string">"./dt/a/img/@src"</span>)[<span class="number">0</span>]</span><br><span class="line">            title = item.xpath(<span class="string">"./dd/a/text()"</span>)[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">            res = &#123;</span><br><span class="line">                <span class="string">'link'</span> : link,</span><br><span class="line">                <span class="string">'photo'</span> : photo,</span><br><span class="line">                <span class="string">'title'</span> : title</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 进入宝贝详情页 开始爬取里面的图片资料</span></span><br><span class="line">            self.getItemDetail(link, <span class="string">''</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取分页信息</span></span><br><span class="line">    pagination = selector.xpath(<span class="string">"//div[@class='pagination']/a[contains(@class, 'J_SearchAsync') and contains(@class, 'next')]/@href"</span>)</span><br><span class="line">    <span class="keyword">print</span> pagination</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'正在准备切换分页'</span></span><br><span class="line">    <span class="keyword">if</span> len(pagination) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'没有下一页了'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'加载下一页内容'</span></span><br><span class="line">        self.site_url = <span class="string">'https:'</span> + pagination[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">print</span> self.site_url</span><br><span class="line">        self.getPage()</span><br><span class="line">```            </span><br><span class="line"></span><br><span class="line">在这里，我们看到我们已经获取到了宝贝的链接，封面图，标题。并且执行了`getItemDetail(self, link, save_img_path)`函数去爬取宝贝的详情页了，最后我们还在循环结束之后，分析了分页数据。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">那么最后，我们就来看看最关键的`getItemDetail()`函数，看看是怎么爬取宝贝信息的:</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getItemDetail</span><span class="params">(self, link, save_img_path)</span>:</span></span><br><span class="line">    <span class="string">"""从宝贝的详情链接里 爬取图片</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        link &#123;String&#125; -- [宝贝详情链接]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    newDriver = webdriver.Chrome()</span><br><span class="line">    newDriver.get(link)</span><br><span class="line">    time.sleep(self.sleep_time)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> newDriver.title</span><br><span class="line"></span><br><span class="line">    img_dir_path = self.save_img_path + newDriver.title.encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">True</span> == self.mkdir(img_dir_path):</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'创建宝贝目录成功'</span></span><br><span class="line"></span><br><span class="line">    html = newDriver.page_source.encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    selector = etree.HTML(html)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 封面图</span></span><br><span class="line">    J_ULThumb = selector.xpath(<span class="string">"//div[@class='tb-gallery']/ul/li"</span>)</span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> J_ULThumb:</span><br><span class="line">        <span class="comment"># 替换图片 从50*50 至 400 * 400</span></span><br><span class="line">        <span class="keyword">if</span> len(li.xpath(<span class="string">"./div/a/img/@data-src"</span>)) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        small_pic = li.xpath(<span class="string">"./div/a/img/@data-src"</span>)[<span class="number">0</span>]</span><br><span class="line">        common_pic = <span class="string">'https:'</span> + small_pic.replace(<span class="string">'50x50'</span>, <span class="string">'400x400'</span>)</span><br><span class="line">        thumb_title = str(<span class="string">'封面图'</span>) + str(index)</span><br><span class="line">        <span class="keyword">print</span> thumb_title</span><br><span class="line">        <span class="comment"># self.saveImg(img_dir_path, common_pic, thumb_title.decode('utf-8'))</span></span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 爬取里面所有图片</span></span><br><span class="line">    all_img = selector.xpath(<span class="string">"//div[@id='J_DivItemDesc']//descendant::img/@src"</span>)</span><br><span class="line">    <span class="keyword">print</span> all_img</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> all_img:</span><br><span class="line">        imglink = img</span><br><span class="line">        <span class="keyword">if</span> img.startswith(<span class="string">'http'</span>) <span class="keyword">is</span> <span class="keyword">True</span>:</span><br><span class="line">            imglink = img</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            imglink = <span class="string">'https:'</span> + img</span><br><span class="line"></span><br><span class="line">        self.saveImg(img_dir_path, imglink, str(index))</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    newDriver.quit()</span><br></pre></td></tr></table></figure>
<p>注释都写在代码里了，大家看看就好，这里有很多地方的代码不够优雅，那是我当天急着用，所以后来也没有去优化了。</p>
<p>在这个核心解析代码的完成之后，宝贝图片就已经稳稳的存储到我们的硬盘上了，可以开箱即用了。完整的代码我也放在了<a href="https://github.com/originalix/Original/blob/master/python2.7/taobaoshop.py" target="_blank" rel="noopener">Github</a>上了，如果对您有帮助，请帮忙star一下。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/07/Python——爬虫实战-爬取淘宝店铺内所有宝贝图片/" data-id="cjogriuyg000uvfz9x6xjfzqg" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
    
 <script src="/jquery/jquery.min.js"></script>
  <div id="random_posts">
    <h2>推荐文章</h2>
    <div class="random_posts_ul">
      <script>
          var random_count =4
          var site = {BASE_URI:'/'};
          function load_random_posts(obj) {
              var arr=site.posts;
              if (!obj) return;
              // var count = $(obj).attr('data-count') || 6;
              for (var i, tmp, n = arr.length; n; i = Math.floor(Math.random() * n), tmp = arr[--n], arr[n] = arr[i], arr[i] = tmp);
              arr = arr.slice(0, random_count);
              var html = '<ul>';
            
              for(var j=0;j<arr.length;j++){
                var item=arr[j];
                html += '<li><strong>' + 
                item.date + ':&nbsp;&nbsp;<a href="' + (site.BASE_URI+item.uri) + '">' + 
                (item.title || item.uri) + '</a></strong>';
                if(item.excerpt){
                  html +='<div class="post-excerpt">'+item.excerpt+'</div>';
                }
                html +='</li>';
                
              }
              $(obj).html(html + '</ul>');
          }
          $('.random_posts_ul').each(function () {
              var c = this;
              if (!site.posts || !site.posts.length){
                  $.getJSON(site.BASE_URI + 'js/posts.js',function(json){site.posts = json;load_random_posts(c)});
              } 
               else{
                load_random_posts(c);
              }
          });
      </script>
    </div>
  </div>

    
<nav id="article-nav">
  
    <a href="/2018/03/14/ES6——扩展运算符使用/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          ES6——扩展运算符使用
        
      </div>
    </a>
  
  
    <a href="/2018/02/27/Python——爬虫入门XPath的使用/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">Python——爬虫入门XPath的使用</div>
    </a>
  
</nav>

  
</article>
 
     
  <div class="comments" id="comments">
    
     
       
       
      
      
  </div>
 
  

</section>
           
    <aside id="sidebar">
  
    

  
    
  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title recent-posts">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/11/14/javascript——为自己的库编写更健壮的API函数/">javascript——为自己的库编写更健壮的API函数</a>
          </li>
        
          <li>
            <a href="/2018/10/09/服务器的Mysql初始化设置/">服务器的Mysql初始化设置</a>
          </li>
        
          <li>
            <a href="/2018/09/19/Ubuntu-16-04服务器的初始化设置/">Ubuntu 16.04服务器的初始化设置</a>
          </li>
        
          <li>
            <a href="/2018/09/09/唠唠快速排序算法/">唠唠快速排序算法</a>
          </li>
        
          <li>
            <a href="/2018/08/28/微信小程序——城市区县定位选择组件/">微信小程序——城市/区县定位选择组件</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    

  
    
  
    <!--微信公众号二维码-->


  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2018 李晓&nbsp;|&nbsp;
      主题 <a href="https://github.com/giscafer/hexo-theme-cafe/" target="_blank">Cafe</a>
    </div>
     <div id="footer-right">
      联系方式&nbsp;|&nbsp;xiao.liunit@gmail.com
    </div>
  </div>
</footer>
 <script src="/jquery/jquery.min.js"></script>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


 <script src="/js/is.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/elevator.js"></script>
  </div>
</body>
</html>